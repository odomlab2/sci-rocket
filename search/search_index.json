{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>sci-rocket is a Snakemake workflow which performs processing of sci-RNA-seq3 sequencing, including barcode demultiplexing and downstream alignment / UMI-counting using STARSolo.</p> <p>Please see the set-up instructions below for more information on how to install and run the workflow.</p>"},{"location":"#pre-requirements","title":"Pre-requirements","text":"<p>There is currently no LSF support yet in latest snakemake (v8). For LSF clusters (e.g. DKFZ), we recommend using snakemake v7.32.4 instead.</p> <ol> <li>A conda system, e.g., conda, mamba or micromamba</li> <li>Snakemake and a cluster-specific Snakemake configuration for batch-job submission (see instructions below).<ul> <li>E.g., LSF or SLURM</li> </ul> </li> </ol> <p>We make use of pre-defined environment(s) which houses all software dependencies (<code>workflow/envs/</code>). These are installed automatically by Snakemake when running the workflow (<code>--use-conda</code>).</p>"},{"location":"#set-up","title":"Set-up","text":"<ol> <li> <p>Clone the repository:</p> <pre><code>git clone https://github.com/odomlab2/sci-rocket\n</code></pre> </li> <li> <p>Download and install snakemake (e.g. using conda or micromamba):</p> <pre><code># This will install snakemake (7.32.4) + Python 3.11.7 into a new conda environment called 'snakemake'\nmicromamba create -c conda-forge -c bioconda -n snakemake snakemake==7.32.4 python==3.11.7 mamba\n# Switch to the 'snakemake' environment\nmicromamba activate snakemake\n</code></pre> </li> <li> <p>Run the workflow:</p> <pre><code>cd workflow/\nsnakemake --use-conda --profile &lt;profile_name&gt; --configfile &lt;path_config&gt;\n</code></pre> </li> </ol> <p>Useful Snakemake parameters:</p> <ul> <li><code>-n</code>: Perform dry-run (generate commands without executing).</li> <li><code>-p</code>: Print shell commands.</li> <li><code>--notemp</code>: Do not remove files flagged as temporary.</li> <li><code>--rerun-incomplete</code>: Rerun all jobs with missing output files.</li> </ul>"},{"location":"#configuration","title":"Configuration","text":"<p>The workflow requires a configuration file (<code>config.yaml</code>) which can be copied from the example configuration file and adjusted to your needs.</p> <p>Within the configuration file, the sample-sheet (<code>path_samples</code>) needs to be specified. This file contains the sample names and paths to the raw sequencing data (BCL or FASTQ).</p>"},{"location":"config_lsf/","title":"LSF profile","text":"<p>These commands were used to set up the LSF profile on the DKFZ LSF cluster.</p>"},{"location":"config_lsf/#run-cookiecutter-template-for-lsf-profile","title":"Run cookiecutter template for LSF profile","text":"<pre><code># Set to your username\nprofile_dir=\"/home/&lt;username&gt;/.config/snakemake\"\nmkdir -p \"$profile_dir\"\n\npython3 -m cookiecutter $profile_dir gh:Snakemake-Profiles/lsf\n</code></pre> <p>When prompted, set the following parameters:</p> <pre><code>LSF_UNIT_FOR_LIMITS=MB\nUNKWN_behaviour=wait\nZOMBI_behaviour=ignore\nlatency-wait=30\nuse_conda=n\nuse-singularity=n\nrestart_times=2\nprint_shell_commands=y\njobs=50 (default)\ndefault_mem_mb=1024 (default)\ndefault_cluster_logdir=logs/cluster\ndefault_queue=long\ndefault_project=&lt;leave empty&gt;\nmax_status_checks_per_second=10 (default)\nmax_jobs_per_second=10 (default)\nmax_status_checks=1 (default)\nwait_between_tries=0.001 (default)\njobscript_timeout=10 (default)\nprofile=lsf_dkfz\n</code></pre>"},{"location":"overview_files/","title":"Sample-sheet and barcodes","text":"<p>See example sample-sheet.</p> <p>sci-rocket requires a sample sheet (.tsv) with at least the following required columns.</p> <p>Either one or both of the following columns:</p> <ul> <li>path_bcl: Path to folder containing the BCL files.</li> <li>path_fastq: Path to folder containing the <code>Undetermined_S0_R1_001.fastq.gz</code> and <code>Undetermined_S0_R2_001.fastq.gz</code> files (if <code>bcl2fastq</code> has already been run).</li> </ul> <p>Additional required columns:</p> <ul> <li>experiment_name: Experiment name (e.g., experimentXYZ), used to associate all downstream files and underlying samples.</li> <li>p5: PCR (p5) index(es) (e.g. A01:H01, or column(s) of a 96-well index plate) used to identify the sample during demultiplexing.</li> <li>p7: PCR (p7) index(es) (e.g. G01:G12, or rows(s) of a 96-well index plate) used to identify the sample during demultiplexing.</li> <li>rt: RT barcode(s) (e.g. P01-A01:P01-A12) used to identify the sample during demultiplexing.</li> <li>sample_name: Name of the demultiplexed sample, used to generate sample-specific files.</li> <li>species: Reference species (e.g. mouse or human).</li> <li>n_expected_cells: Number of expected cells in the (demultiplexed) sample (used during UMI filtering).</li> </ul> <ul> <li>p5 and p7 are used to denote the PCR indexes belonging to a particular sample / cell. The indexes are translated to all relevant combinations within the sequencing-run using the 96-well index plate layout of 8x rows (A:H) and 12 columns (01:12). To specify one or multiple p5/p7 ranges, use the following format:</li> <li>p5 (1 column): <code>A01:H01</code></li> <li>p5 (1.5 columns): <code>A01:H01,A02:D02</code></li> <li>p5 (2 columns): <code>A01:H01,A02:H02</code></li> <li>p7 (1 row): <code>G01:G12</code></li> <li>p7 (1.5 rows): <code>G01:G12,H01:H06</code></li> <li>p7 (2 rows): <code>G01:G12,H01:H12</code></li> <li>The rt is used to denote the RT barcode belonging to a particular sample / cell. The indexes are translated to all relevant combinations within the sequencing-run. To specify one or multiple RT strips, use the following format:</li> <li>One RT: <code>P01-A01</code></li> <li>Multiple RT (1 row): <code>P01-A01:P01-A12</code></li> <li>Multiple RT (1 column): <code>P01-A01:P01-H01</code></li> <li>Multiple RT (2 columns): <code>P01-A01:P01-H02</code></li> <li>Multiple RT (rectangular region): <code>P01-B02:P01-E04</code>; This will include all RT barcodes from the rectangle with P01-B02 at the top left and P01-E04 at the bottom right:</li> </ul> P01 1 2 3 4 5 A . . . . . B . X X X . C . X X X . D . X X X . E . X X X . F . . . . . <ul> <li> <p>Multiple RT (multiple plates): <code>P01-B02:P01-E04,P02-A01:P02-A12</code>; This will include the same RT barcodes from P01 as the previous example, plus row A from P02.</p> </li> <li> <p>species should be present in the <code>config.yaml</code> file with their respective genome sequences (.fa) and gene-annotations (.gtf) used to generate mapping indexes.</p> </li> </ul>"},{"location":"overview_files/#barcode-design","title":"Barcode design","text":"<p>The workflow requires a file (.tsv) containing the barcodes used in the experiment with at least the following required columns:</p> <ul> <li>type: Type of barcode (<code>ligation</code>, <code>p5</code>, <code>p7</code> or <code>rt</code>).</li> <li>barcode: Name of the barcode (e.g. A01).</li> <li>sequence: Nucleotide sequence of the barcode.</li> </ul>"},{"location":"overview_files/#hashing-sheet","title":"Hashing sheet","text":"<p>The hashing workflow requires a separate file (.tsv) containing the hashing schematics used in the sample with at least the following required columns:</p> <ul> <li>hash_name: Name of the hashing experiment (e.g. hash_exp1).</li> <li>barcode: Sequence of the respective hashing barcode (e.g. GGTTGGCGAC).</li> </ul> <p>To specify which samples are to be hashed (and using which hashing-sheet), add an additional column (<code>hashing</code>) in the sample-sheet to each each sample with the respective path to the hashing sheet.</p>"},{"location":"overview_files/#haplotyping-optional-mus-musculus-cross-experiments-only","title":"Haplotyping (optional; Mus musculus cross-experiments only)","text":"<p>As optional procedure, sci-rocket can be used to further haplotype the sex-chromosome X of the demultiplexed samples, e.g. in the case of mouse F1 cross-hybrids. For this, the following columns can be added to the sample-sheet:</p> <ul> <li>strain1: Name of the first strain (e.g. B6 (C57BL/6J)).</li> <li>strain2: Name of the second strain (e.g. CAST/EiJ).</li> </ul> <p>These strains should be present in the Mouse Genome Project (MGP) database. For C57BL/6J (wt), use <code>B6</code> as strain name.</p> <p>This will add haplotype-specific read tags (HP) to the STARSolo BAM files and will output an additional <code>haplotyping</code> folder which contains cell-based read-counts per gene per haplotype (H1, H2, UA) for chromosome X.</p>"},{"location":"overview_methodology/","title":"Methodology","text":"<p>See here for more information on the library generation of the sci-RNA-Seq3 protocol.</p>"},{"location":"overview_methodology/#major-steps","title":"Major steps","text":"<ol> <li>Check for sanity of provided barcodes and sample-sheet.</li> <li>Converts BCL files to paired-end .fq.gz files with PCR indexes in header (bcl2fastq).</li> <li>Merges multiple sequencing runs (<code>path_bcl</code>) into one experiment-based file (<code>experiment_name</code>).</li> <li>Splits paired-end .fq.fz files into smaller (evenly-sized) chunks for parallelization (fastqsplitter).</li> <li>Demultiplexing using the supplied sample-specific barcodes (sci-rocket).</li> <li>Finds exact or nearest match for PCR Index #1 (p5), PCR Index #1 (p7), ligation and/or RT barcode (single match with \u22641 hamming distance).</li> <li>Generates sample-specific .fastq.gz files with corrected R1 sequence (48nt) and added read-names in R2.</li> <li>Read-pairs without all four matching barcodes are discarded into separate .fastq.gz files with logs detailing which barcode(s) are (non-)matching.</li> <li>For samples with a specified hashing sheet, additional hashing procedures are performed.</li> <li>Performs adapter and low-quality base-trimming (fastp).</li> <li>Read-pairs with a mate \u226410nt after trimming are discarded.</li> <li>Aligns reads to the supplied reference genome and perform cell-barcode/UMI counting (STARSolo).</li> <li>STAR index can be generated based on supplied genome sequences and annotations.</li> <li>Per gene and cellular barcode, intronic, exonics and UTR-overlapping reads (UMI) are counted and multi-mapping reads are distributed using the <code>EM</code> method.</li> <li>Generate demultiplexing/alignment overview. (sci-dash)</li> <li>Generates a HTML report with demultiplexing and alignment statistics.</li> </ol> <p>Parallization is performed per experiment_name and split chunk.</p>"},{"location":"overview_methodology/#optional-steps","title":"Optional steps","text":"<ol> <li>(Mus musculus-only) Haplotype demultiplexing.</li> <li>Adds haplotype-specific read tags (HP) to the STARSolo BAM files using known haplotype-specific SNPs (MGP + haplotag).</li> <li>Generate haplotype-specific read-counts per gene per cell (H1, H2, UA) (umi_tools).</li> </ol>"},{"location":"overview_methodology/#downstream-analysis","title":"Downstream analysis","text":"<p>For downstream analysis, we also maintain an R package to analyze results produced by sci-rocket called scir.</p>"},{"location":"overview_methodology/#sample-demultiplexing-without-hashing","title":"Sample demultiplexing (without hashing)","text":"<p>Example of R1 sequence:</p> <pre><code>      @READNAME 1:N:0:CCGTATGATT+AGATGCAACT\n                        |----p7---|+|----p5----|: p5 is reverse-complemented during demuxxing.\n      ACTTGATTGTCAGAGCTTTGGTATCCTACCAGTT\n\n      The R1 sequence should adhere to the following scheme:\n      First 9 or 10nt:  Ligation barcode\n      Next 6nt:    Primer\n      Next 8nt:    UMI\n      Last 10nt:   RT Barcode (sample-specific)\n\n      Anatomy of R1 (ligation of 10nt):\n      |ACTTGATTGT| |CAGAGC| |TTTGGTAT| |CCTACCAGTT|\n      |-LIGATION-| |Primer| |---UMI--| |----RT----|\n\n      Anatomy of R1 (ligation of 9nt):\n      |CTCGTTGAT| |CAGAGC| |TTTGGTAT| |CCTACCAGTT| |T|\n      |-LIGATION| |Primer| |---UMI--| |----RT----| |.| &lt;- Extra base.\n\n      Corrected R1 sequence (48nt):\n      |CCGTATGATT| |AGTTGCATCT| |CTCGTTGAT| |CCTACCAGTT| |TTTGGTAT|\n      |----p7----| |----p5----| |-LIGATION-| |----RT----| |---UMI--|\n</code></pre> <p>For sample-demultiplexing, the following steps are performed:</p> <ol> <li>Extracts p5, p7 PCR indexes from the read-name of R1 and ligation, RT and UMI barcodes from sequence of read 1 (R1).</li> <li>If no match, corrects p5, p7, ligation and/or RT barcode to nearest match (with max. 1nt difference). If multiple close matches, discard read-pair.</li> <li>For ligation barcodes of 9nt in length, an extra G is added to the ligation sequence as padding to ensure 48nt R1 sequence.</li> <li>Add the barcodes to the read-names of read 1 and 2: <code>@READNAME|P5-&lt;p5&gt;-P7-&lt;p7&gt;|&lt;ligation&gt;|&lt;rt&gt;_&lt;UMI&gt;</code></li> <li>Generate sample-specific paired-end fq.gz files with corrected R1 sequence (48nt) and R2 sequence.</li> </ol>"},{"location":"overview_methodology/#hashing","title":"Hashing","text":"<p>Reads (R2) containing both a polyA signal (AAAA) and a hashing barcode are used to flag reads as hashing-reads. These reads are used for collecting hashing metrics (with their respective R1) and subsequently removed from the analysis.</p> <p>To flag reads as hashing-reads, we first check for the presence of the polyA signal (AAAA) in R2 (first occurence). If this signal is present, we check for the presence of the hashing barcode in R2 prior to this poly-A signal. It is assumed that the hashing barcodes are 10nt and are (directly) prior to the poly-A signal (5' - 1nt spacer).</p> <p>If no match is found using the first 10nt (5' poly-A - 1nt spacer) ; we try again against the closest match (hamming distance=1). If no rescued match is found, we search for the presence of any hashing barcode in the entire R2 sequence prior to the poly-A signal.</p> <p>The following metrics are generated from hashing reads, per cellular barcode / hash barcode combination:</p> <pre><code>sequencing_name   hash_barcode    cell_barcode    count    n_umi\ntest            AGGTAGAGCT      F07_D09_LIG98_P01-C08      100      10\ntest            ACGTTGAATG      F07_D09_LIG98_P01-C08      200      15\n</code></pre> <p>These metrics are used to determine the hashing efficiency and to correct for UMI bias in downstream analysis:</p> <ul> <li>count: Total number of hashing reads for that specific cell-barcode / hash-barcode combination.</li> <li>n_umi: Number of unique UMIs for that specific cell-barcode / hash-barcode combination.</li> </ul>"},{"location":"overview_methodology/#haplotyping-optional-mus-musculus-cross-experiments-only","title":"Haplotyping (optional; Mus musculus cross-experiments only)","text":"<p>As optional procedure, sci-rocket can be used to further haplotype the sex-chromosome X of the demultiplexed samples, e.g. in the case of mouse F1 cross-hybrids, see here for more information. This will download (or symlink) the MGP database and perform haplotype-specific read-counting using whatshap on F1-informative heterozygous SNPs.</p>"},{"location":"overview_methodology/#output","title":"Output","text":"<p>The major output files are the following:</p> <ol> <li>Sequence and sample-specific fastq file(s):</li> <li><code>{experiment_name}/demux_reads/{sample_name}_R1.fastq.gz</code></li> <li><code>{experiment_name}/demux_reads/{sample_name}_R2.fastq.gz</code></li> <li><code>{experiment_name}/demux_reads/{sample_name}_R1_discarded.fastq.gz</code></li> <li><code>{experiment_name}/demux_reads/{sample_name}_R2_discarded.fastq.gz</code></li> <li><code>{experiment_name}/demux_reads/log_{sample_name}_discarded_reads.tsv.gz</code></li> <li>Alignment files:</li> <li><code>{experiment_name}/alignment/{sample_name}_{species}_Aligned.sortedByCoord.out.bam/bai</code></li> <li><code>{experiment_name}/alignment/{sample_name}_{species}_Solo.out/</code></li> <li>Demultiplexing/alignment overview:</li> <li><code>{experiment_name}/sci-dash/</code></li> <li>Logging and benchmarking:</li> <li><code>{experiment_name}/logs/</code></li> <li><code>{experiment_name}/benchmarking/</code></li> </ol>"}]}